{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: c:\\Users\\Dolly\\.conda\\envs\\hackathon\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "diffusion_pytorch_model.safetensors not found\n",
      "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]An error occurred while trying to fetch C:\\Users\\Dolly\\.cache\\huggingface\\hub\\models--google--ddpm-celebahq-256\\snapshots\\cd5c944777ea2668051904ead6cc120739b86c4d: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\Dolly\\.cache\\huggingface\\hub\\models--google--ddpm-celebahq-256\\snapshots\\cd5c944777ea2668051904ead6cc120739b86c4d.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|██████████| 2/2 [00:00<00:00,  5.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from utils import load_epsilon_net, load_image\n",
    "from utils import load_epsilon_net\n",
    "from sampling.dps import dps, dps_save\n",
    "from sampling.dps_dpms import dps_dpms_save, dps_dpms\n",
    "from sampling.dmps import dpms_save, dpms\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import display_image\n",
    "import os\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from evaluation.perception import LPIPS\n",
    "import glob\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "def make_gif(frame_folder, n_steps):\n",
    "    frames = [Image.open(image) for image in sorted(glob.glob(f\"{frame_folder}/*.png\"))[::-1]]\n",
    "    print(frame_folder)\n",
    "    frame_one = frames[0]\n",
    "    frame_one.save(frame_folder+\"/output.gif\", format=\"GIF\", append_images=frames,\n",
    "               save_all=True, duration=300, loop=0)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "#n_steps = 100\n",
    "torch.set_default_device(device)\n",
    "\n",
    "\n",
    "img_path = \"./hackathon_starter_kit/material/celebahq_img/00010.jpg\"\n",
    "x_origin = load_image(img_path, device = device, resize = (256, 256))\n",
    "if x_origin.shape[0] == 4:\n",
    "    x_origin = x_origin[:3, :, :]\n",
    "\n",
    "\n",
    "# load the degradation operator\n",
    "path_operator = f\"./hackathon_starter_kit/material/degradation_operators/sr16.pt\"\n",
    "#path_operator = f\"./hackathon_starter_kit/material/degradation_operators/inpainting_middle.pt\" #TODO: update operator path\n",
    "degradation_operator = torch.load(path_operator, map_location=device)\n",
    "operator_type = \"sr16\" #TODO: update operator type\n",
    "\n",
    "# apply degradation operator\n",
    "y = degradation_operator.H(x_origin[None])\n",
    "y = y.squeeze(0)\n",
    "\n",
    "sigma = [0.01]\n",
    "n_steps = [100]\n",
    "\n",
    "\n",
    "methods = [\"dps\", \"dpms\", \"dps_dpms\"]\n",
    "\n",
    "output_base= \"./output/sr16/\" #TODO: update output base\n",
    "lpips = LPIPS()\n",
    "\n",
    "for n in n_steps:\n",
    "    for s in sigma:\n",
    "        K = [50]\n",
    "        for k in K:\n",
    "\n",
    "            # add noise\n",
    "            y = y + s * torch.randn_like(y)\n",
    "\n",
    "            # define inverse problem\n",
    "            inverse_problem = (y, degradation_operator, s)\n",
    "\n",
    "            # load model\n",
    "            eps_net = load_epsilon_net(\"celebahq\", n, device)\n",
    "\n",
    "            # solve problem\n",
    "            initial_noise = torch.randn((1, 3, 256, 256), device=device)\n",
    "\n",
    "\n",
    "            #make output dir\n",
    "            if \"dps\" in methods:\n",
    "                seed = 2024\n",
    "                torch.manual_seed(seed=seed) # for reproducibility\n",
    "\n",
    "                output_dir = os.path.join(output_base, f\"dps_n_step={n}_sigma={s}\")\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                time_dps_start = time()\n",
    "                #reconstruction_dps = dps_save(initial_noise, inverse_problem, eps_net, output_path=output_dir, interval=1)\n",
    "                reconstruction_dps = dps(initial_noise, inverse_problem, eps_net)\n",
    "                time_dps_end = time()\n",
    "                time_dps = time_dps_end - time_dps_start\n",
    "            if \"dps_dpms\" in methods:\n",
    "                seed = 2024\n",
    "                torch.manual_seed(seed=seed) # for reproducibility\n",
    "\n",
    "                output_dir = os.path.join(output_base, f\"dps_dpms_n_step={n}_sigma={s}\")\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                time_dps_dpms_start = time()\n",
    "                #reconstruction_dps_dpms = dps_dpms_save(initial_noise, inverse_problem, eps_net, lam = 1, k = k, output_path=output_dir, interval=1)\n",
    "                reconstruction_dps_dpms = dps_dpms(initial_noise, inverse_problem, eps_net, k=k)\n",
    "                time_dps_dpms_end = time()\n",
    "                time_dps_dpms= time_dps_dpms_end - time_dps_dpms_start\n",
    "            if \"dpms\" in methods:\n",
    "                seed = 2024\n",
    "                torch.manual_seed(seed=seed) # for reproducibility\n",
    "\n",
    "                output_dir = os.path.join(output_base, f\"dpms_n_step={n}_sigma={s}_k={k}\")\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                time_dpms_start = time()\n",
    "                #reconstruction_dpms = dpms_save(initial_noise, inverse_problem, eps_net, output_path=output_dir, interval=1)\n",
    "                reconstruction_dpms = dpms(initial_noise, inverse_problem, eps_net)\n",
    "                time_dpms_end = time()\n",
    "                time_dpms = time_dpms_end - time_dpms_start\n",
    "            \n",
    "            #make_gif(output_dir, n_steps)\n",
    "\n",
    "            if \"sr\" in operator_type:\n",
    "                n_channels = 3\n",
    "                n_pixel_per_channel = y.shape[0] // n_channels\n",
    "                hight = width = int(math.sqrt(n_pixel_per_channel))\n",
    "\n",
    "                y_reshaped = y.reshape(n_channels, hight, width)\n",
    "\n",
    "            else:\n",
    "\n",
    "                y_reshaped =  -torch.ones(3 * 256 * 256, device=device)\n",
    "                y_reshaped[: y.shape[0]] = y\n",
    "                y_reshaped = degradation_operator.V(y_reshaped[None])\n",
    "                y_reshaped = y_reshaped.reshape(3, 256, 256)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 5, figsize = (20, 20))\n",
    "\n",
    "            images = (x_origin, y_reshaped, reconstruction_dps[0], reconstruction_dpms[0],reconstruction_dps_dpms[0])\n",
    "            titles = (\"original\", \"degraded\", \"DPS\", \"DPMS\", f\"DPS-DMPS (k={k})\")\n",
    "\n",
    "            # display figures\n",
    "            \n",
    "            for ax, img, title in zip(axes, images,titles):\n",
    "                display_image(img, ax)\n",
    "                ax.set_title(title, fontsize = 25)\n",
    "                ax.set_axis_off() \n",
    "                if title == \"DPS\":\n",
    "                    psnr_dps = round(psnr(x_origin.cpu().numpy(), reconstruction_dps[0].cpu().numpy()), 3)\n",
    "                    lpips_dps = round(lpips.score(x_origin, reconstruction_dps[0].clamp(-1, 1)).item(), 3)\n",
    "                    ax.text(10, 280, \"PSNR:\"+str(psnr_dps)+\"dB\", fontsize=21, color = (0,0,0))           \n",
    "                    ax.text(10, 300, \"LPIPS:\"+str(lpips_dps), fontsize=21, color = (0,0,0))  \n",
    "                    ax.text(10 ,320, \"Time:\"+str(round(time_dps, 3))+ \"s\", fontsize=21, color = (0,0,0))\n",
    "\n",
    "                elif title == \"DPMS\":\n",
    "                    psnr_dpms = round(psnr(x_origin.cpu().numpy(), reconstruction_dpms[0].cpu().numpy()), 3)\n",
    "                    lpips_dpms = round(lpips.score(x_origin, reconstruction_dpms[0].clamp(-1, 1)).item(), 3)\n",
    "                    ax.text(10, 280, \"PSNR:\"+str(psnr_dpms)+\"dB\", fontsize=21, color = (0,0,0))           \n",
    "                    ax.text(10, 300, \"LPIPS:\"+str(lpips_dpms), fontsize=21, color = (0,0,0))\n",
    "                    ax.text(10 ,320, \"Time:\"+str(round(time_dpms, 3))+ \"s\", fontsize=21, color = (0,0,0))   \n",
    "\n",
    "                elif \"DPS-DMPS\" in title:\n",
    "                    psnr_dps_dpms = round(psnr(x_origin.cpu().numpy(), reconstruction_dps_dpms[0].cpu().numpy()), 3)\n",
    "                    lpips_dps_dpms =  round(lpips.score(x_origin, reconstruction_dps_dpms[0].clamp(-1, 1)).item(), 3)\n",
    "                    ax.text(10, 280, \"PSNR:\"+str(psnr_dps_dpms)+\"dB\", fontsize=21, color = (0,0,0))           \n",
    "                    ax.text(10 ,300, \"LPIPS:\"+str(lpips_dps_dpms), fontsize=21, color = (0,0,0))    \n",
    "                    ax.text(10 ,320, \"Time:\"+str(round(time_dps_dpms, 3))+ \"s\", fontsize=21, color = (0,0,0))    \n",
    "\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(output_base+f\"/{operator_type}_output_n_step={n}_sigma={s}_k={k}.png\", bbox_inches = \"tight\")\n",
    "\n",
    "            plt.close(fig)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
